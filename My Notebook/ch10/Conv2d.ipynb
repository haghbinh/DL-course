{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.25, inplace=False)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): Dropout(p=0.25, inplace=False)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  (9): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    # Conv2D layer with 3 input channels (e.g., RGB image), 6 output channels, 3x3 kernel\n",
    "    nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, \n",
    "              padding=1, stride=1, dilation=1),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    # Dropout layer (e.g., 25% drop rate)\n",
    "    nn.Dropout(p=0.25),\n",
    "    \n",
    "    # Max Pooling layer with 2x2 kernel and stride of 2\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    # Another Conv2D layer (6 input channels, 12 output channels, 3x3 kernel)\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, \n",
    "              padding=1, stride=1, dilation=1),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    # Dropout layer (e.g., 25% drop rate)\n",
    "    nn.Dropout(p=0.25),\n",
    "    \n",
    "    # Max Pooling layer with 2x2 kernel and stride of 2\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    # Flatten the output to feed into a fully connected layer\n",
    "    nn.Flatten(),\n",
    "    \n",
    "    # Fully connected layer (simple output layer with 10 output classes, for example)\n",
    "    nn.Linear(12 * 8 * 8, 10)  # Adjust input size based on input size and Conv2D output\n",
    ")\n",
    "\n",
    "# Example of model summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 3, 32, 32])\n",
      "Output shape: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming the model is already defined as in the previous example\n",
    "\n",
    "# Create a random input tensor simulating a batch of 4 RGB images of size 32x32\n",
    "input_tensor = torch.randn(4, 3, 32, 32)  # Shape: (batch_size, channels, height, width)\n",
    "\n",
    "# Print the shape of the input tensor\n",
    "print(f'Input shape: {input_tensor.shape}')\n",
    "\n",
    "# Pass the input through the model\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(f'Output shape: {output_tensor.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2424832/9912422 [00:26<01:09, 108264.54it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 2. Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)  # Input channels: 1 (grayscale)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Adjust input size for the linear layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 7 * 7)  # Flatten the output\n",
    "        x = self.dropout(nn.functional.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# 3. Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Train the model\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)  # Accumulate loss\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Average loss for the epoch\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# 5. Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "        total += labels.size(0)  # Total number of labels\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Plot training loss over epochs\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 2. Define the CNN model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=5, padding=2),  # Input channels: 1 (grayscale)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Dropout(p=0.5),\n",
    "    \n",
    "    nn.Flatten(),  # Flatten the output for the fully connected layer\n",
    "    nn.Linear(32 * 7 * 7, 128),  # Adjust input size for the linear layer\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(128, 10)  # Output layer with 10 classes\n",
    ")\n",
    "\n",
    "# 3. Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Train the model\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)  # Accumulate loss\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Average loss for the epoch\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# 5. Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted classes\n",
    "        total += labels.size(0)  # Total number of labels\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Plot training loss over epochs\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
